{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167d5bd0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import pipeline\n",
    "from data.window import SlidingWindow\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664444fd-2e5e-4513-899f-bd6d56e73f88",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7322d8b7-d484-47f9-8ecf-338a8d437a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LSTM dataset\n",
      "Done!\n",
      "(1050578, 4, 8) (1050578, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load / Build dataset\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = pipeline.load(\"LSTM\") # load / buildAndSave / build\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21c98a7-d777-4031-8931-df9e1f3e6497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050578, 4, 8) (1050578, 1)\n"
     ]
    }
   ],
   "source": [
    "# Normalisation\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = X_train.reshape(-1, 32)\n",
    "X_test = X_test.reshape(-1, 32)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "sc_y = StandardScaler()\n",
    "Y_train = sc_y.fit_transform(Y_train.reshape(-1, 1))\n",
    "\n",
    "X_train = X_train.reshape(-1, 4, 8)\n",
    "X_test = X_test.reshape(-1, 4, 8)\n",
    "\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30903884",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10e42ce-8aed-4dc4-8de1-b0196bda78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for training and tuning\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner import BayesianOptimization, Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e52780c-4512-4be2-965c-184aa9475f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\lstm_automl\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\lstm_automl\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Define how to implement the model\n",
    "\n",
    "def implement_model(units, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units= units,\n",
    "                   activation= 'relu',\n",
    "                   input_shape= (4, 8)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer= Adam(learning_rate= learning_rate),\n",
    "                  loss= 'mean_squared_error',\n",
    "                  metrics= [RootMeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define how to build the model with hyperparameters\n",
    "\n",
    "def build_model(hp):\n",
    "    # Tune the number of units in the LSTM per cell in the layer\n",
    "    # units between 50-90\n",
    "    hp_units = hp.Int('units', min_value= 50, max_value= 90, step= 2)\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # learning_rate from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    model = implement_model(hp_units, hp_learning_rate)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define the tuner\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    hypermodel= build_model,\n",
    "    objective= Objective('val_root_mean_squared_error', direction= 'min'),\n",
    "    num_initial_points= 2,\n",
    "    executions_per_trial= 3,\n",
    "    project_name= 'lstm_automl',\n",
    "    overwrite= False # True at first search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0c02e-4822-4a78-a06b-db1588eadb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #9\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "70                |68                |units\n",
      "0.005834          |0.0064156         |learning_rate\n",
      "\n",
      "Epoch 1/10\n",
      "32831/32831 [==============================] - 107s 3ms/step - loss: 0.0812 - root_mean_squared_error: 0.2850 - val_loss: 2013.8969 - val_root_mean_squared_error: 44.8765\n",
      "Epoch 2/10\n",
      "32831/32831 [==============================] - 107s 3ms/step - loss: 0.0635 - root_mean_squared_error: 0.2519 - val_loss: 2008.9790 - val_root_mean_squared_error: 44.8216\n",
      "Epoch 3/10\n",
      "32831/32831 [==============================] - 110s 3ms/step - loss: 0.0591 - root_mean_squared_error: 0.2430 - val_loss: 2008.0253 - val_root_mean_squared_error: 44.8110\n",
      "Epoch 4/10\n",
      "32831/32831 [==============================] - 120s 4ms/step - loss: 0.0558 - root_mean_squared_error: 0.2363 - val_loss: 2009.4447 - val_root_mean_squared_error: 44.8268\n",
      "Epoch 5/10\n",
      "32831/32831 [==============================] - 118s 4ms/step - loss: 0.2397 - root_mean_squared_error: 0.4895 - val_loss: 2013.7533 - val_root_mean_squared_error: 44.8749\n",
      "Epoch 6/10\n",
      "32831/32831 [==============================] - 118s 4ms/step - loss: 0.3379 - root_mean_squared_error: 0.5813 - val_loss: 2015.2491 - val_root_mean_squared_error: 44.8915\n",
      "Epoch 7/10\n",
      "32831/32831 [==============================] - 117s 4ms/step - loss: 0.3592 - root_mean_squared_error: 0.5993 - val_loss: 2007.8782 - val_root_mean_squared_error: 44.8094\n",
      "Epoch 8/10\n",
      "32831/32831 [==============================] - 117s 4ms/step - loss: 4.0533 - root_mean_squared_error: 2.0133 - val_loss: 2016.9020 - val_root_mean_squared_error: 44.9099\n",
      "Epoch 9/10\n",
      "32831/32831 [==============================] - 117s 4ms/step - loss: 1.4113 - root_mean_squared_error: 1.1880 - val_loss: 2008.1906 - val_root_mean_squared_error: 44.8128\n",
      "Epoch 10/10\n",
      "32831/32831 [==============================] - 119s 4ms/step - loss: 17.4701 - root_mean_squared_error: 4.1797 - val_loss: 2170.4709 - val_root_mean_squared_error: 46.5883\n",
      "Epoch 1/10\n",
      "32831/32831 [==============================] - 120s 4ms/step - loss: 0.0811 - root_mean_squared_error: 0.2847 - val_loss: 2008.9064 - val_root_mean_squared_error: 44.8208\n",
      "Epoch 2/10\n",
      "32831/32831 [==============================] - 124s 4ms/step - loss: 0.0636 - root_mean_squared_error: 0.2522 - val_loss: 2008.6609 - val_root_mean_squared_error: 44.8181\n",
      "Epoch 3/10\n",
      "32831/32831 [==============================] - 122s 4ms/step - loss: 0.0587 - root_mean_squared_error: 0.2422 - val_loss: 2012.4374 - val_root_mean_squared_error: 44.8602\n",
      "Epoch 4/10\n",
      "32831/32831 [==============================] - 120s 4ms/step - loss: 0.0804 - root_mean_squared_error: 0.2836 - val_loss: 2008.7363 - val_root_mean_squared_error: 44.8189\n",
      "Epoch 5/10\n",
      "32831/32831 [==============================] - 120s 4ms/step - loss: 0.1216 - root_mean_squared_error: 0.3488 - val_loss: 2010.9646 - val_root_mean_squared_error: 44.8438\n",
      "Epoch 6/10\n",
      "32831/32831 [==============================] - 123s 4ms/step - loss: 0.2826 - root_mean_squared_error: 0.5316 - val_loss: 2009.7509 - val_root_mean_squared_error: 44.8302\n",
      "Epoch 8/10\n",
      "32831/32831 [==============================] - 128s 4ms/step - loss: 2.3137 - root_mean_squared_error: 1.5211 - val_loss: 2018.8907 - val_root_mean_squared_error: 44.9321\n",
      "Epoch 10/10\n",
      "32831/32831 [==============================] - 132s 4ms/step - loss: 0.2789 - root_mean_squared_error: 0.5281 - val_loss: 2014.8809 - val_root_mean_squared_error: 44.8874\n",
      "Epoch 1/10\n",
      "32831/32831 [==============================] - 121s 4ms/step - loss: 0.0633 - root_mean_squared_error: 0.2517 - val_loss: 2009.1707 - val_root_mean_squared_error: 44.8238\n",
      "Epoch 3/10\n",
      "32831/32831 [==============================] - 122s 4ms/step - loss: 0.0876 - root_mean_squared_error: 0.2960 - val_loss: 2006.5493 - val_root_mean_squared_error: 44.7945\n",
      "Epoch 5/10\n",
      "32831/32831 [==============================] - 119s 4ms/step - loss: 0.0693 - root_mean_squared_error: 0.2633 - val_loss: 2007.0612 - val_root_mean_squared_error: 44.8002\n",
      "Epoch 6/10\n",
      "32831/32831 [==============================] - 115s 4ms/step - loss: 9.0384 - root_mean_squared_error: 3.0064 - val_loss: 2027.7162 - val_root_mean_squared_error: 45.0302\n",
      "Epoch 8/10\n",
      "32831/32831 [==============================] - 117s 4ms/step - loss: 5.0357 - root_mean_squared_error: 2.2440 - val_loss: 2010.7101 - val_root_mean_squared_error: 44.8409\n",
      "Epoch 9/10\n",
      "13025/32831 [==========>...................] - ETA: 52s - loss: 0.2334 - root_mean_squared_error: 0.4831"
     ]
    }
   ],
   "source": [
    "# Reload the tuner\n",
    "\n",
    "tuner.reload() # Deactivate at first search\n",
    "\n",
    "\n",
    "# Search the best hyperparameters\n",
    "\n",
    "history=tuner.search(x= X_train, y= Y_train, epochs= 10, validation_data=(X_test, Y_test))\n",
    "\n",
    "\n",
    "# Get the results of the tuning\n",
    "\n",
    "tuner.results_summary()\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"The best:\n",
    "- dimension of the hidden state found is {best_hps.get('units')}\n",
    "- learning rate found is {best_hps.get('learning_rate')}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18958d7c-0530-4cae-bea6-8a5b39500903",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reload the model from the tuner\n",
    "\n",
    "tuner.reload()\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "\n",
    "# Implement the model with default hyperparameters\n",
    "\n",
    "#model = implement_model(units= 70, learning_rate= 0.005)\n",
    "\n",
    "\n",
    "# Initialise Tensorboard to visualise the loss\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117aab6b-1c95-4580-b9be-f949c8ddaf94",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs= 10, callbacks= [tensorboard_callback])\n",
    "%tensorboard --logdir logs/gradient_tape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82306ba6-e734-4d1c-8683-41082f994712",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d79fca-e515-4dac-8bc8-e6534e053405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the size of the test dataset\n",
    "\n",
    "X_test = X_test[:999]\n",
    "Y_test = Y_test[:999]\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2887a341-2790-4099-a9b5-73f2e93fbc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "decades_per_year = 37\n",
    "Y_naive = [Y_test[4:4+decades_per_year].mean()]*3\n",
    "for decade in range(3, len(Y_test), decades_per_year):\n",
    "    growth_avg = Y_test[decade:decade + decades_per_year].mean()\n",
    "    Y_naive += [growth_avg] * decades_per_year\n",
    "\n",
    "print('Test RMSE with naive model : %.3f' % sqrt(mean_squared_error(Y_test, Y_naive[3:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89717a9f-5f55-4980-aa06-53723dac1bd0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sw = SlidingWindow(X_test, reset_cycle= 37)\n",
    "\n",
    "pred = model.predict(sw.values.reshape(-1, 4, 8), verbose=0) # iterator: 0\n",
    "Y_preds = [pred]\n",
    "\n",
    "last_progression = 0\n",
    "print(0, '%')\n",
    "while sw.next(pred): # iterator: t-1\n",
    "    arg = sw.values.reshape(-1, 4, 8)\n",
    "    pred = model.predict(sw.values.reshape(-1, 4, 8), verbose=0) # iterator: t\n",
    "    if np.isnan(pred):\n",
    "        print(arg)\n",
    "    Y_preds.append(pred)\n",
    "        \n",
    "    progression = (sw.it+1) / len(X_test) * 100\n",
    "    if progression - last_progression > 1 and not int(progression) % 10:\n",
    "        print(int(progression), '%')\n",
    "        last_progression = progression\n",
    "\n",
    "Y_preds = np.array(Y_preds).reshape(-1)\n",
    "\n",
    "print('Test RMSE : %.3f' % sqrt(mean_squared_error(Y_test, Y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d874672-ac0d-4a05-8bde-e969146c207b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y_preds = sc_y.inverse_transform(Y_preds.reshape(1, -1))\n",
    "Y_preds = Y_preds.reshape(-1)\n",
    "Y_test = Y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e1539-3bfc-4303-91c8-e2802edb9d92",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "year = 5\n",
    "decades = [decade for decade in range(37)]\n",
    "plt.plot(decades, [None]*3 + list(Y_test[37*year:37*(year+1)-3]), color=\"blue\", label= \"raw\")\n",
    "plt.plot(decades, [9.57]*3 + list(Y_preds[37*year:37*(year+1)-3]), color=\"red\", label= \"LSTM\")\n",
    "plt.plot(decades, Y_naive[37*year:37*(year+1)], color=\"green\", label= \"naive model\")\n",
    "plt.xlabel(\"Decades\")\n",
    "plt.ylabel(\"Growth\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9083ddcc-539b-4c86-b84d-b0422341788b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
